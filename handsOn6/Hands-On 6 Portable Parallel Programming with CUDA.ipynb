{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5aff66a6-3d99-4cb7-aef3-471aca80301e",
      "metadata": {
        "id": "5aff66a6-3d99-4cb7-aef3-471aca80301e"
      },
      "source": [
        "# Hands-On 6: Portable Parallel Programming with CUDA\n",
        "*   Enzo Bacelar Conte Gebauer\n",
        "*   Luiz Guilherme Guerreiro\n",
        "*   Maria Eduarda Lopes de Morais Brito"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26eb3b74-e057-4432-9617-64f3ef61477a",
      "metadata": {
        "id": "26eb3b74-e057-4432-9617-64f3ef61477a"
      },
      "source": [
        "## `Especificações`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7045a1f5",
      "metadata": {
        "id": "7045a1f5"
      },
      "source": [
        "    GPU: RTX 4060 ti 8GB\n",
        "    CPU: AMD Ryzen 7 5700x\n",
        "    RAM: 16 GB 3200 mhz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c086de9a-1313-4788-a5f6-20753781bee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c086de9a-1313-4788-a5f6-20753781bee5",
        "outputId": "11a07831-3660-4c6f-96f3-82134267b8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting saxpy.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile saxpy.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "__global__ void saxpy(int n, float *x, float *y){\n",
        "int i = threadIdx.x;\n",
        "if(i < n)\n",
        "y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "void printVector(float *vector, int n)\n",
        "{\n",
        "\n",
        " for (int i=0; i < n ; ++i)\n",
        "  printf(\"%1.0f\\t\", vector[i]);\n",
        "\n",
        "  printf(\"\\n\\n\");\n",
        "}\n",
        "\n",
        "void generateVector(float *vector, int n)\n",
        "{\n",
        " for (int i=0; i < n ; ++i)\n",
        "  vector[i] = i + 1;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "  int n = atoi(argv[1]);\n",
        "  float *x,*y;\n",
        "\n",
        "  x = (float*) malloc(sizeof(float) * n);\n",
        "  y = (float*) malloc(sizeof(float) * n);\n",
        "\n",
        "  generateVector(x, n);\n",
        "  printVector(x, n);\n",
        "\n",
        "  generateVector(y, n);\n",
        "  printVector(y, n);\n",
        "\n",
        "  float *xd, *yd;\n",
        "\n",
        "  cudaMalloc( (void**)&xd, sizeof(float) * n );\n",
        "  cudaMalloc( (void**)&yd, sizeof(float) * n );\n",
        "\n",
        "  cudaMemcpy(xd, x, sizeof(float) * n, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(yd, y, sizeof(float) * n, cudaMemcpyHostToDevice);\n",
        "\n",
        "  int NUMBER_OF_BLOCKS = 1;\n",
        "  int NUMBER_OF_THREADS_PER_BLOCK = n;\n",
        "  saxpy<<< NUMBER_OF_BLOCKS, NUMBER_OF_THREADS_PER_BLOCK >>>(n, xd, yd);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  cudaMemcpy(y, yd, sizeof(float) * (n), cudaMemcpyDeviceToHost);\n",
        "  printVector(y, n);\n",
        "\n",
        "  cudaFree(xd);\n",
        "  cudaFree(yd);\n",
        "\n",
        "  free(x);\n",
        "  free(y);\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ef67a7-4ab2-4b9c-b1cc-a654c009922c",
      "metadata": {
        "id": "64ef67a7-4ab2-4b9c-b1cc-a654c009922c"
      },
      "source": [
        "## Run the Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a32f54a-c29e-4dc4-8ea9-696e4c6931f8",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "0a32f54a-c29e-4dc4-8ea9-696e4c6931f8"
      },
      "outputs": [],
      "source": [
        "!nvcc saxpy.cu -o saxpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "37c1dfb0-b8b8-4286-ae5b-ebc7d3fa8f4b",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c1dfb0-b8b8-4286-ae5b-ebc7d3fa8f4b",
        "outputId": "448752b6-fb03-4df1-df7f-0c0c08f73fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t\n",
            "\n",
            "1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t\n",
            "\n",
            "2\t4\t6\t8\t10\t12\t14\t16\t18\t20\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!./saxpy 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195dcbd0-d193-4f80-b41a-10abcc9296e9",
      "metadata": {
        "id": "195dcbd0-d193-4f80-b41a-10abcc9296e9"
      },
      "source": [
        "## `Unified Memory (cudaMallocManaged)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d465562c-5ca7-4ae8-9251-6062f0bb5e70",
      "metadata": {
        "id": "d465562c-5ca7-4ae8-9251-6062f0bb5e70"
      },
      "source": [
        "The program in `saxpy-cudaMallocManaged.cu` allocates memory, using `cudaMallocManaged` for a $n$ elements array of integers, and then seeks to initialize all the values of the array in parallel using a CUDA kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "63a6a8c0-7d93-4239-9082-14477fc3aac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63a6a8c0-7d93-4239-9082-14477fc3aac2",
        "outputId": "9870b3ff-dfb9-4dd0-bf9e-ba082e68fa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing saxpy-cudaMallocManaged.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile saxpy-cudaMallocManaged.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void saxpy(int n,  float *x, float *y){\n",
        " int i = threadIdx.x;\n",
        " if(i < n)\n",
        "   y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "void printVector(float *vector, int n){\n",
        "for (int i=0; i < n ; ++i)\n",
        " printf(\"%1.0f\\t\", vector[i]);\n",
        "printf(\"\\n\\n\");\n",
        "}\n",
        "\n",
        "void generateVector(float *vector, int n){\n",
        "for (int i=0; i < n ; ++i)\n",
        " vector[i] = i + 1;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]){\n",
        "  int n = atoi(argv[1]);\n",
        "  float *x,*y;\n",
        "\n",
        "  cudaMallocManaged(&x, sizeof(float) * n);\n",
        "  cudaMallocManaged(&y, sizeof(float) * n);\n",
        "\n",
        "  generateVector(x, n);\n",
        "  printVector(x, n);\n",
        "  generateVector(y, n);\n",
        "  printVector(y, n);\n",
        "\n",
        "  int NUMBER_OF_BLOCKS = 1;\n",
        "  int NUMBER_OF_THREADS_PER_BLOCK = n;\n",
        "\n",
        "  saxpy <<< NUMBER_OF_BLOCKS, NUMBER_OF_THREADS_PER_BLOCK >>> (n, x, y);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  printVector(y, n);\n",
        "\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e66fa38f-dd55-4127-9b6d-266704484da0",
      "metadata": {
        "id": "e66fa38f-dd55-4127-9b6d-266704484da0"
      },
      "source": [
        "## Run the Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5d592464-2ab8-431f-b869-6c8a9fd81dad",
      "metadata": {
        "id": "5d592464-2ab8-431f-b869-6c8a9fd81dad"
      },
      "outputs": [],
      "source": [
        "!nvcc saxpy-cudaMallocManaged.cu -o saxpy-cudaMallocManaged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "32be91b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32be91b3",
        "outputId": "7ce1e9e5-6dca-499e-9bc4-8b76136077e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t2\t3\t4\t5\t6\t7\t8\t\n",
            "\n",
            "1\t2\t3\t4\t5\t6\t7\t8\t\n",
            "\n",
            "2\t4\t6\t8\t10\t12\t14\t16\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!./saxpy-cudaMallocManaged 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec9a094",
      "metadata": {
        "id": "9ec9a094"
      },
      "source": [
        "## Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b259b561",
      "metadata": {
        "id": "b259b561"
      },
      "source": [
        "\n",
        "### How Unified Memory works?\n",
        "Unified memory allocates the data in a common space between the Host and the accelerator, so when any device needs to use that data, there is no need to send it to the host or device. It simplifies the code and makes the code shorter.\n",
        "\n",
        "### Is cudaMallocManaged slower than cudaMalloc?\n",
        "Yes, cudaMallocManaged can be slower than cudaMalloc because it has to manage memory in a way that's accessible by both the CPU and GPU, involving additional overhead. cudaMallocManaged deals with Unified Memory, meaning it handles data migration between CPU and GPU, which can introduce some latency due to the automatic data management and potential page faults. cudaMalloc, on the other hand, allocates memory directly on the GPU, avoiding the overhead associated with unified memory management. In practice, using cudaMalloc with explicit data transfer might offer better performance, especially in scenarios where fine-grained control over data transfers between the CPU and GPU is critical. However, it might complicate the code by adding manual memory management tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181fc27e-22a5-423f-be01-e2e055adc2fa",
      "metadata": {
        "tags": [],
        "id": "181fc27e-22a5-423f-be01-e2e055adc2fa"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332627cc-a1b3-4d13-854f-5e621ddc264b",
      "metadata": {
        "id": "332627cc-a1b3-4d13-854f-5e621ddc264b"
      },
      "source": [
        "M. Boratto. Hands-On Supercomputing with Parallel Computing. Available: https://github.com/muriloboratto/Hands-On-Supercomputing-with-Parallel-Computing. 2022."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}